{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5719,"status":"ok","timestamp":1705518853553,"user":{"displayName":"Marcos Paulo Silva G么lo","userId":"00854347238887874462"},"user_tz":180},"id":"4kdMfefYfrS3","outputId":"458d9106-a65f-440c-e063-a10e3361162e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\", force_remount = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"femrMVlsgCy4"},"outputs":[],"source":["PATH_TO_GAE_GRAPHS = \"/content/drive/MyDrive/USP/Doctorate/Research/Articles/Early Fusion For One-class Learning On Heterogeneous Graphs/grafos_gae\""]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":253,"status":"ok","timestamp":1705520342584,"user":{"displayName":"Marcos Paulo Silva G么lo","userId":"00854347238887874462"},"user_tz":180},"id":"4TINhKmwhpqx"},"outputs":[],"source":["from sklearn.model_selection import ParameterGrid\n","\n","HYPERPARAMETER_GRID = [\n","{\n","    'conv_type': [\"GCN\"],\n","    'hidden': [[32], [64], [32, 32], [64, 64]],\n","    'lr': [1e-2, 1e-3, 1e-4],\n","    'patience': [50, 100]\n","},\n","{\n","    'conv_type': [\"GRAPHSAGE\"],\n","    'aggr': ['mean', 'max'],\n","    'hidden': [[32], [64], [32, 32], [64, 64]],\n","    'lr': [1e-2, 1e-3, 1e-4],\n","    'patience': [50, 100]\n","},\n","{\n","    'conv_type': [\"GAT\"],\n","    'heads': [4, 8],\n","    'hidden': [[32], [64], [32, 32], [64, 64]],\n","    'lr': [1e-2, 1e-3, 1e-4],\n","    'patience': [50, 100]\n","}]\n","\n","hyperparameter_list_gae = {'GCN' : list(ParameterGrid(HYPERPARAMETER_GRID[0])),\n","                           'GRAPHSAGE' : list(ParameterGrid(HYPERPARAMETER_GRID[1])),\n","                           'GAT' : list(ParameterGrid(HYPERPARAMETER_GRID[2]))}"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":268,"status":"ok","timestamp":1705520344974,"user":{"displayName":"Marcos Paulo Silva G么lo","userId":"00854347238887874462"},"user_tz":180},"id":"t6Aicp85ga1B","outputId":"e63594b1-edb5-44d5-9ef0-6db593e330ce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['rec_sys_1',\n"," 'rec_sys_3',\n"," 'rec_sys_2',\n"," 'rec_sys_4',\n"," 'event',\n"," 'rec_sys_5',\n"," 'music',\n"," 'fakenews']"]},"metadata":{},"execution_count":62}],"source":["import os\n","\n","graphs = os.listdir(PATH_TO_GAE_GRAPHS)\n","graphs"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"4wmHQirQ3n6E","executionInfo":{"status":"ok","timestamp":1705520269940,"user_tz":180,"elapsed":285,"user":{"displayName":"Marcos Paulo Silva G么lo","userId":"00854347238887874462"}}},"outputs":[],"source":["from pandas.core.base import value_counts\n","from sklearn.metrics import classification_report, roc_auc_score\n","import numpy as np\n","import time\n","from pathlib import Path\n","from sklearn.svm import OneClassSVM as OCSVM\n","from sklearn.model_selection import KFold\n","\n","def define_gammas():\n","  gammas = ['scale', 'auto']\n","  return gammas\n","\n","def define_nus():\n","  nus = []\n","  for n in range(5,90,5):\n","    nus.append(n/100)\n","  for n in range(5,90,5):\n","    nus.append(n/1000)\n","\n","  return nus\n","\n","def define_kernels():\n","  return ['rbf', 'sigmoid', 'linear', 'poly']\n","\n","def evaluation_one_class(preds_interest, preds_outliers):\n","    y_true = [1] * len(preds_interest) + [-1] * len(preds_outliers)\n","    y_pred = list(preds_interest) + list(preds_outliers)\n","    return classification_report(y_true, y_pred, output_dict=True)\n","\n","def evaluate_model(X_train, X_test, X_outlier, model):\n","\n","    one_class_classifier = model.fit(X_train)\n","\n","    Y_pred_interest = one_class_classifier.predict(X_test)\n","\n","    Y_pred_ruido = one_class_classifier.predict(X_outlier)\n","\n","    y_true = np.array([1] * len(X_test) + [-1] * len(X_outlier))\n","\n","    dic = evaluation_one_class(Y_pred_interest, Y_pred_ruido)\n","\n","    return dic\n","\n","def init_metrics():\n","    metrics = {\n","        '1': {\n","            'precision': [],\n","            'recall': [],\n","            'f1-score': []\n","        },\n","        '-1': {\n","            'precision': [],\n","            'recall': [],\n","            'f1-score': []\n","        },\n","        'macro avg': {\n","            'precision': [],\n","            'recall': [],\n","            'f1-score': []\n","        },\n","        'weighted avg': {\n","            'precision': [],\n","            'recall': [],\n","            'f1-score': []\n","        },\n","        'accuracy': [],\n","        'time': []\n","    }\n","    return metrics\n","\n","\n","def save_values(metrics, values):\n","    for key in metrics.keys():\n","      if key == 'accuracy' or key == 'time':\n","        metrics[key].append(values[key])\n","      else:\n","        for key2 in metrics[key].keys():\n","          metrics[key][key2].append(values[key][key2])\n","\n","\n","def operation(graph, list_nodes, representation_name, operador, dataset):\n","  x = []\n","\n","  for node in list_nodes:\n","    rep = graph.nodes[node][representation_name]\n","\n","    if dataset == 'event' :\n","      dic_rep = {'what' : [],\n","                 'when' : [],\n","                 'where' : [],\n","                 'who' : [],\n","                 'how' : [],\n","                 'cluster_code' : [],\n","                 'iptc_code': []}\n","\n","      for n in graph.neighbors(node):\n","        for key in dic_rep:\n","          if key in n:\n","             dic_rep[key].append(graph.nodes[n][representation_name])\n","\n","      for key in dic_rep:\n","        dic_rep[key] = np.mean(dic_rep[key], axis=0)\n","\n","      new_rep=None\n","      if operator == 'concatenate':\n","        new_rep = np.concatenate([rep, dic_rep['what'], dic_rep['when'], dic_rep['where'], dic_rep['who'], dic_rep['how'], dic_rep['cluster_code'], dic_rep['iptc_code']])\n","      elif operator == 'sum':\n","        new_rep = np.sum([rep, dic_rep['what'], dic_rep['when'], dic_rep['where'], dic_rep['who'], dic_rep['how'], dic_rep['cluster_code'], dic_rep['iptc_code']], axis=0)\n","      elif operator == 'sub':\n","        new_rep = rep\n","        for key in dic_rep:\n","          new_rep = np.subtract(new_rep, dic_rep[key])\n","      elif operator == 'avg':\n","        new_rep = np.mean([rep, dic_rep['what'], dic_rep['when'], dic_rep['where'], dic_rep['who'], dic_rep['how'], dic_rep['cluster_code'], dic_rep['iptc_code']], axis=0)\n","      elif operator == 'min':\n","        new_rep = np.min([rep, dic_rep['what'], dic_rep['when'], dic_rep['where'], dic_rep['who'], dic_rep['how'], dic_rep['cluster_code'], dic_rep['iptc_code']], axis=0)\n","      elif operator == 'max':\n","        new_rep = np.max([rep, dic_rep['what'], dic_rep['when'], dic_rep['where'], dic_rep['who'], dic_rep['how'], dic_rep['cluster_code'], dic_rep['iptc_code']], axis=0)\n","      elif operator == 'multiply':\n","        new_rep = rep\n","        for key in dic_rep:\n","          new_rep = np.multiply(new_rep, dic_rep[key])\n","\n","    else:\n","      reps = []\n","      for n in graph.neighbors(node):\n","        reps.append(graph.nodes[n][representation_name])\n","\n","      rep_o = np.mean(reps, axis=0)\n","\n","      new_rep=None\n","      if operator == 'concatenate':\n","        new_rep = np.concatenate([rep, rep_o])\n","      elif operator == 'sum':\n","        new_rep = np.sum([rep, rep_o], axis=0)\n","      elif operator == 'sub':\n","        new_rep = np.subtract(rep, rep_o)\n","      elif operator == 'avg':\n","        new_rep = np.mean([rep, rep_o], axis=0)\n","      elif operator == 'min':\n","        new_rep = np.min([rep, rep_o], axis=0)\n","      elif operator == 'max':\n","        new_rep = np.max([rep, rep_o], axis=0)\n","      elif operator == 'multiply':\n","        new_rep = np.multiply(rep, rep_o)\n","\n","    x.append(new_rep)\n","\n","  return x\n","\n","def extract_emb_from_graph(graph, representation_name, interest_class, nodes_train, nodes_test, nodes_out, operator, principal_node, dataset):\n","\n","  if operator == 'without':\n","    x_train, x_int_test, x_nint_test = [], [], []\n","\n","    for node in nodes_train:\n","      x_train.append(graph.nodes[node][representation_name])\n","\n","    for node in nodes_test:\n","      x_int_test.append(graph.nodes[node][representation_name])\n","\n","    for node in nodes_out:\n","      x_nint_test.append(graph.nodes[node][representation_name])\n","  else:\n","    x_train = operation(graph, nodes_train, representation_name, operator, dataset)\n","    x_int_test = operation(graph, nodes_test, representation_name, operator, dataset)\n","    x_nint_test = operation(graph, nodes_out, representation_name, operator, dataset)\n","\n","  return x_train, x_int_test, x_nint_test\n","\n","def evaluate_models(G, representation_name, path, file_name, hyperparams_gae, interest_class, l_int, l_nint, operator, principal_node, dataset):\n","\n","    kf = KFold(n_splits=5, shuffle=True, random_state=81)\n","\n","    for kernel in define_kernels():\n","      for gamma in define_gammas():\n","        for nu in define_nus():\n","          ocsvm = OCSVM(kernel=kernel,nu=nu,gamma=gamma)\n","          line_parameters = str(hyperparams_gae) + '_kernel:' + kernel + '_gamma:' + gamma + '_nu:' + str(nu)\n","          metrics = init_metrics()\n","\n","          for train_index, test_index in kf.split(l_int):\n","            nodes_train = np.array(l_int)[train_index]\n","            nodes_test = np.array(l_int)[test_index]\n","\n","            x_train, x_int_test,x_nint_test = extract_emb_from_graph(G, representation_name, interest_class, nodes_train, nodes_test, l_nint, operator, principal_node, dataset)\n","\n","            start = time.time()\n","            values = evaluate_model(x_train, x_int_test, x_nint_test, ocsvm)\n","            end = time.time()\n","            time_ = end - start\n","            values['time'] = time_\n","            save_values(metrics, values)\n","\n","          write_results(metrics, file_name, line_parameters, path)\n","\n","\n","def write_results(metrics, file_name, line_parameters, path):\n","    if not Path(path + file_name).is_file():\n","        file_ = open(path + file_name, 'w')\n","        string = 'Parameters'\n","        for key in metrics.keys():\n","            if key == 'accuracy' or key == 'time':\n","              string += ';' + key + '-mean;' + key + '-std'\n","            else:\n","              for key2 in metrics[key].keys():\n","                string += ';' + key + '_' + key2 + '-mean;' + key + '_' + key2 + '-std'\n","\n","        string += '\\n'\n","        file_.write(string)\n","        file_.close()\n","\n","    file_ = open(path + file_name, 'a')\n","    string = line_parameters\n","\n","    for key in metrics.keys():\n","      if key == 'accuracy' or key == 'time':\n","        string += ';' + str(np.mean(metrics[key])) + ';' + str(np.std(metrics[key]))\n","      else:\n","        for key2 in metrics[key].keys():\n","          string += ';' + str(np.mean(metrics[key][key2])) + ';' + str(np.std(metrics[key][key2]))\n","\n","    string += '\\n'\n","    file_.write(string)\n","    file_.close()\n"]},{"cell_type":"markdown","metadata":{"id":"o-2jETIK3Op4"},"source":["# Music"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e8ughtveIxWD"},"outputs":[],"source":["import pickle as pkl\n","import networkx as nx\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","GNN = 'GRAPHSAGE'\n","\n","path_results = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/Early Fusion For One-class Learning On Heterogeneous Graphs/resultados/' + GNN + '/'\n","\n","dataset = 'music'\n","\n","interest_class = 'hit'\n","\n","principal_node = 'song'"]},{"cell_type":"markdown","source":["## REG"],"metadata":{"id":"4arRkZ8iPcUj"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbKKN0FD3R38"},"outputs":[],"source":["for operator in ['without', 'sum', 'sub', 'avg', 'min', 'max', 'multiply', 'concatenate']:\n","  for hyperparams_gae, pickle in zip(hyperparameter_list_gae, os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}\")):\n","    print(f\"Dataset: {dataset} - GAE Hyperparameters: {hyperparams_gae}\")\n","    with open(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{pickle}\", \"rb\") as file:\n","      G = pkl.load(file)\n","\n","      l_int, l_nint = [], []\n","      for node in G.nodes():\n","        if principal_node in node and G.nodes[node]['label'] == interest_class:\n","          l_int.append(node)\n","        elif principal_node in node and G.nodes[node]['label'] != interest_class:\n","          l_nint.append(node)\n","\n","      evaluate_models(G, 'f_features', path_results, dataset + '_' + operator + '.csv', 'reg', interest_class, l_int, l_nint, operator, principal_node, dataset)\n","      break"]},{"cell_type":"markdown","source":["## GAE"],"metadata":{"id":"qVI0cp_TPfgS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfQIdHTJFpYf"},"outputs":[],"source":["for operator in ['without', 'sum', 'sub', 'avg', 'min', 'max', 'multiply', 'concatenate']:\n","  print(operator)\n","  for hyperparams_gae, pickle in zip(hyperparameter_list_gae[GNN], os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}/\")):\n","    print(f\"Dataset: {dataset} - GAE Hyperparameters: {hyperparams_gae}\")\n","    with open(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}/{pickle}\", \"rb\") as file:\n","      G = pkl.load(file)\n","\n","      l_int, l_nint = [], []\n","      for node in G.nodes():\n","        if principal_node in node and G.nodes[node]['label'] == interest_class:\n","          l_int.append(node)\n","        elif principal_node in node and G.nodes[node]['label'] != interest_class:\n","          l_nint.append(node)\n","\n","      evaluate_models(G, 'gae_features', path_results, dataset + '-gae_' + operator + '.csv', hyperparams_gae, interest_class, l_int, l_nint, operator, principal_node, dataset)"]},{"cell_type":"markdown","metadata":{"id":"bt-tYmzUZRa7"},"source":["# fakenews\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkizgDEGPlbj"},"outputs":[],"source":["import pickle as pkl\n","import networkx as nx\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","GNN = 'GRAPHSAGE'\n","\n","path_results = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/Early Fusion For One-class Learning On Heterogeneous Graphs/resultados/' + GNN + '/'\n","\n","dataset = 'fakenews'\n","\n","interest_class = 'fake'"]},{"cell_type":"markdown","source":["## REG"],"metadata":{"id":"LSmTqZkmPowC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXQLECkJZTMO"},"outputs":[],"source":["for operator in ['concatenate', 'without', 'sum', 'sub', 'avg', 'min', 'max', 'multiply']:\n","  for hyperparams_gae, pickle in zip(hyperparameter_list_gae, os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}\")):\n","    print(f\"Dataset: {dataset} - GAE Hyperparameters: {hyperparams_gae}\")\n","    with open(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{pickle}\", \"rb\") as file:\n","      G = pkl.load(file)\n","\n","      l_int, l_nint = [], []\n","      for node in G.nodes():\n","        if type(node) == int and G.nodes[node]['label'] == interest_class:\n","          l_int.append(node)\n","        elif type(node) == int and G.nodes[node]['label'] != interest_class:\n","          l_nint.append(node)\n","\n","      evaluate_models(G, 'f_features', path_results, dataset + '_' + operator + '.csv', 'reg', interest_class, l_int, l_nint, operator, '', dataset)\n","      break"]},{"cell_type":"markdown","source":["## GAE"],"metadata":{"id":"vzHO6ktDPqjz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aeqKNDb33iYU"},"outputs":[],"source":["for operator in ['without', 'sum', 'sub', 'avg', 'min', 'max', 'multiply', 'concatenate']:\n","  print(operator)\n","  for hyperparams_gae, pickle in zip(hyperparameter_list_gae[GNN], os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}/\")):\n","    print(f\"Dataset: {dataset} - GAE Hyperparameters: {hyperparams_gae}\")\n","    with open(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}/{pickle}\", \"rb\") as file:\n","      G = pkl.load(file)\n","\n","      l_int, l_nint = [], []\n","      for node in G.nodes():\n","        if type(node) == int and G.nodes[node]['label'] == interest_class:\n","          l_int.append(node)\n","        elif type(node) == int and G.nodes[node]['label'] != interest_class:\n","          l_nint.append(node)\n","\n","      evaluate_models(G, 'gae_features', path_results, dataset + '-gae_' + operator + '.csv', hyperparams_gae, interest_class, l_int, l_nint, operator, '', dataset)"]},{"cell_type":"markdown","metadata":{"id":"7NM_eW-kG1ov"},"source":["# Eventos"]},{"cell_type":"code","source":["import pickle as pkl\n","import networkx as nx\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","GNN = 'GAT'\n","\n","path_results = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/Early Fusion For One-class Learning On Heterogeneous Graphs/resultados/' + GNN + '/'\n","\n","dataset = 'event'\n","\n","interest_class = 'f1'\n","\n","principal_node = 'event'"],"metadata":{"id":"H0sm01hzQXHQ","executionInfo":{"status":"ok","timestamp":1705520535835,"user_tz":180,"elapsed":264,"user":{"displayName":"Marcos Paulo Silva G么lo","userId":"00854347238887874462"}}},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":["## REG"],"metadata":{"id":"_dFwEEL5cUUR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"YePyExNmG4_M"},"outputs":[],"source":["for operator in ['concatenate', 'min', 'without', 'sum', 'sub', 'avg', 'max', 'multiply']:\n","  for hyperparams_gae, pickle in zip(hyperparameter_list_gae, os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}\")):\n","    print(f\"Dataset: {dataset} - GAE Hyperparameters: {hyperparams_gae}\")\n","    with open(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{pickle}\", \"rb\") as file:\n","      G = pkl.load(file)\n","\n","      l_int, l_nint = [], []\n","      for node in G.nodes():\n","        if principal_node in node and G.nodes[node]['label'] == interest_class:\n","          l_int.append(node)\n","        elif principal_node in node and G.nodes[node]['label'] != interest_class:\n","          l_nint.append(node)\n","\n","      evaluate_models(G, 'f_features', path_results, dataset + '_' + operator + '.csv', 'reg', interest_class, l_int, l_nint, operator, principal_node, dataset)\n","      break"]},{"cell_type":"markdown","source":["## GAE"],"metadata":{"id":"mAuqduHMcVzX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"3HPiwgsbJx8N"},"outputs":[],"source":["for operator in ['without', 'sum', 'sub', 'avg', 'min', 'max', 'multiply', 'concatenate']:\n","  print(operator)\n","  for hyperparams_gae, pickle in zip(hyperparameter_list_gae[GNN], os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}/\")):\n","    print(f\"Dataset: {dataset} - GAE Hyperparameters: {hyperparams_gae}\")\n","    with open(f\"{PATH_TO_GAE_GRAPHS}/{dataset}/{GNN}/{pickle}\", \"rb\") as file:\n","      G = pkl.load(file)\n","\n","      l_int, l_nint = [], []\n","      for node in G.nodes():\n","        if principal_node in node and G.nodes[node]['label'] == interest_class:\n","          l_int.append(node)\n","        elif principal_node in node and G.nodes[node]['label'] != interest_class:\n","          l_nint.append(node)\n","\n","      evaluate_models(G, 'gae_features', path_results, dataset + '-gae_' + operator + '.csv', hyperparams_gae, interest_class, l_int, l_nint, operator, principal_node, dataset)"]},{"cell_type":"markdown","metadata":{"id":"zM0-syZtJ7Rv"},"source":["# Rec Sys"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EPw4B99wMkiX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684014510268,"user_tz":180,"elapsed":2660,"user":{"displayName":"Marcos Paulo Silva G么lo","userId":"00854347238887874462"}},"outputId":"66838e93-7b85-46b8-e587-f000f7bff409"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1XFiH0-J1r9DepyhfAzQUCe8pIClddNHw\n","To: /content/df_interest.pkl\n","100% 624k/624k [00:00<00:00, 24.6MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1U-qJ0Aayp2srzlIxiztEpTjIolp9fWya\n","To: /content/df_outlier.pkl\n","100% 171k/171k [00:00<00:00, 80.7MB/s]\n"]}],"source":["!gdown 1XFiH0-J1r9DepyhfAzQUCe8pIClddNHw\n","!gdown 1U-qJ0Aayp2srzlIxiztEpTjIolp9fWya"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwX9qHC7NT2Z"},"outputs":[],"source":["import pandas as pd\n","\n","df_int = pd.read_pickle('df_interest.pkl')\n","df_out = pd.read_pickle('df_outlier.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r93t9-UCNO5k"},"outputs":[],"source":["def train_test_split_ocl_recommendation(kf, df_int):\n","    train_test = []\n","\n","    for train_index, test_index in kf.split(df_int):\n","        train_test.append((df_int.iloc[train_index], df_int.iloc[test_index]))\n","\n","    return train_test\n","\n","def foldValidation(folds):\n","    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n","    return kf\n","\n","def operation(graph, representation_name, operator, dataset, df_train, df):\n","\n","  users = df_train['user'].unique()\n","  items = df_train['item'].unique()\n","\n","  x = []\n","\n","  for index,row in df.iterrows():\n","    continue_ = 0\n","    user = str(row['user']) + ':user'\n","    item = str(row['item']) + ':item'\n","\n","    if user in graph.nodes() and item in graph.nodes():\n","      rep_i = graph.nodes[item][representation_name]\n","\n","      rep_u = graph.nodes[user][representation_name]\n","\n","      dic_rep = {'review' : [],\n","                  'genre' : [],\n","                  'keyword' : []}\n","\n","      for n in graph.neighbors(item):\n","        for key in dic_rep:\n","          if key in n:\n","            dic_rep[key].append(graph.nodes[n][representation_name])\n","\n","      for key in dic_rep:\n","        if len(dic_rep[key]) == 0:\n","          continue_ = 1\n","        else:\n","          dic_rep[key] = np.mean(dic_rep[key], axis=0)\n","\n","      if continue_ == 0 :\n","        new_rep=None\n","        if operator == 'concatenate':\n","          new_rep = np.concatenate([rep_i, rep_u, dic_rep['review'], dic_rep['genre'], dic_rep['keyword']])\n","        elif operator == 'sum':\n","          new_rep = np.sum([rep_i, rep_u, dic_rep['review'], dic_rep['genre'], dic_rep['keyword']], axis=0)\n","        elif operator == 'sub':\n","          new_rep = np.subtract(rep_i, rep_u)\n","          for key in dic_rep:\n","            new_rep = np.subtract(new_rep, dic_rep[key])\n","        elif operator == 'avg':\n","          new_rep = np.mean([rep_i, rep_u, dic_rep['review'], dic_rep['genre'], dic_rep['keyword']], axis=0)\n","        elif operator == 'min':\n","          new_rep = np.min([rep_i, rep_u, dic_rep['review'], dic_rep['genre'], dic_rep['keyword']], axis=0)\n","        elif operator == 'max':\n","          new_rep = np.max([rep_i, rep_u, dic_rep['review'], dic_rep['genre'], dic_rep['keyword']], axis=0)\n","        elif operator == 'multiply':\n","          new_rep = np.multiply(rep_i, rep_u)\n","          for key in dic_rep:\n","            new_rep = np.multiply(new_rep, dic_rep[key])\n","\n","        x.append(new_rep)\n","\n","  return x\n","\n","def extract_emb_from_graph(graph, representation_name, operator, df_train, df_test, df_out):\n","\n","  users = df_train['user'].unique()\n","  items = df_train['item'].unique()\n","\n","  if operator == 'without':\n","    x_train, x_int_test, x_nint_test = [], [], []\n","\n","    for index,row in df_train.iterrows():\n","      user = str(row['user']) + ':user'\n","      item = str(row['item']) + ':item'\n","      if user in graph.nodes() and item in graph.nodes():\n","        x_train.append(np.concatenate([graph.nodes[user][representation_name], graph.nodes[item][representation_name]]))\n","\n","    for index,row in df_test.iterrows():\n","      user = str(row['user']) + ':user'\n","      item = str(row['item']) + ':item'\n","      if user in graph.nodes() and item in graph.nodes():\n","        x_int_test.append(np.concatenate([graph.nodes[user][representation_name], graph.nodes[item][representation_name]]))\n","\n","    for index,row in df_out.iterrows():\n","      user = str(row['user']) + ':user'\n","      item = str(row['item']) + ':item'\n","      if user in graph.nodes() and item in graph.nodes():\n","        x_nint_test.append(np.concatenate([graph.nodes[user][representation_name], graph.nodes[item][representation_name]]))\n","\n","  else:\n","    x_train = operation(graph, representation_name, operator, dataset, df_train, df_train)\n","    x_int_test = operation(graph,representation_name, operator, dataset, df_train, df_test)\n","    x_nint_test = operation(graph, representation_name, operator, dataset, df_train, df_out)\n","\n","  return x_train, x_int_test, x_nint_test\n","\n","def evaluate_rec_sys(representation_name, path, file_name, hyperparams_gae, operator, dataset, train_test, df_out, pickle):\n","\n","  for kernel in define_kernels():\n","    if kernel != 'rbf':\n","      for gamma in define_gammas():\n","        for nu in define_nus():\n","          ocsvm = OCSVM(kernel=kernel,nu=nu,gamma=gamma)\n","          metrics = init_metrics()\n","\n","          line_parameters = str(hyperparams_gae) + '_kernel:' + kernel + '_gamma:' + gamma + '_nu:' + str(nu)\n","          for i in range(1,5):\n","            df_train, df_test = train_test[i]\n","\n","            with open(f\"{PATH_TO_GAE_GRAPHS}/{dataset}_{i}/{GNN}/{pickle}\", \"rb\") as file:\n","              G = pkl.load(file)\n","\n","              x_train, x_int_test, x_nint_test = extract_emb_from_graph(G, representation_name, operator, df_train, df_test, df_out)\n","\n","              start = time.time()\n","              values = evaluate_model(x_train, x_int_test, x_nint_test, ocsvm)\n","              end = time.time()\n","              time_ = end - start\n","              values['time'] = time_\n","              save_values(metrics, values)\n","\n","          write_results(metrics, file_name, line_parameters, path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QT9e5UddNXpk"},"outputs":[],"source":["import pickle as pkl\n","import networkx as nx\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","GNN = 'GRAPHSAGE'\n","\n","path_results = '/content/drive/MyDrive/USP/Doctorate/Research/Articles/Early Fusion For One-class Learning On Heterogeneous Graphs/resultados/' + GNN + '/'\n","\n","dataset = 'rec_sys'\n","\n","principal_node = ''\n","\n","folds = 5\n","kf = foldValidation(folds)\n","train_test = train_test_split_ocl_recommendation(kf, df_int)"]},{"cell_type":"markdown","source":["## REG"],"metadata":{"id":"7ZzncE5HQ4y_"}},{"cell_type":"code","source":["for operator in ['without', 'sum', 'sub', 'avg', 'min', 'max', 'multiply', 'concatenate']:\n","  evaluate_rec_sys('f_features', path_results, dataset + '_' + operator + '.csv', 'reg', operator, dataset, train_test, df_out, os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}_1/{GNN}/\")[0])"],"metadata":{"id":"JI0A-kUoQ6wI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GAE"],"metadata":{"id":"G_q10oh-Q8iX"}},{"cell_type":"code","source":["for operator in ['without', 'sum', 'sub', 'avg', 'min', 'max', 'multiply', 'concatenate']:\n","  for hyperparams_gae, pickle in zip(hyperparameter_list_gae[GNN], os.listdir(f\"{PATH_TO_GAE_GRAPHS}/{dataset}_1/{GNN}\")):\n","    evaluate_rec_sys('gae_features', path_results, dataset + '_' + operator + '.csv', hyperparams_gae, operator, dataset, train_test, df_out, pickle)"],"metadata":{"id":"G4TLABT5Q70Y"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}